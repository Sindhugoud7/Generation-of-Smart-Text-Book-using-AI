# importing required libraries:
import os
import openai
import time
import requests
import urllib.parse
from docx import Document
from docx.shared import Inches
from bs4 import BeautifulSoup
from PIL import Image
import shutil
import aspose.words as aw


APIKEY = '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'
openai.api_key = APIKEY
source_folder = 'D:/Python IDE/APISmartBook/'
destination_folder = 'C:/Users/Gowrilatha/Downloads'

doc = Document()


# code to scrape links
def get_video_links(keyword, api_key):
    base_url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        "part": "id",
        "q": urllib.parse.quote(keyword),
        "type": "video",
        "key": api_key,
        "maxResults": 5,  # Change this value to get more or fewer results
    }

    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status()
    except requests.exceptions.RequestException as err:
        print("Error occurred:", err)
        return []

    data = response.json()
    video_links = []

    for item in data["items"]:
        video_id = item["id"]["videoId"]
        video_links.append(f"https://www.youtube.com/watch?v={video_id}")

    return video_links


# code to scrape images
def extract_images(topic):
    # Create a directory to store the images
    os.makedirs(topic, exist_ok=True)

    # URL to search for images
    url = f"https://www.google.com/search?q={topic}&source=lnms&tbm=isch"

    # Send a GET request to the URL
    response = requests.get(url)

    # Create a BeautifulSoup object to parse the HTML content
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <img> tags
    img_tags = soup.find_all('img')

    # Counter to keep track of the image number
    img_num = 1

    # Download and save each image
    for img in img_tags:
        try:
            img_url = img['src']

            # Send a GET request to download the image
            img_response = requests.get(img_url)

            # Check if the response is an image
            if img_response.headers.get('content-type', '').startswith('image'):
                # Save the image as a PNG file
                with open(f"{topic}/image{img_num}.png", "wb") as f:
                    f.write(img_response.content)

                img_num += 1
        except:
            continue


# Algorithm
def get_answer(question):
    prompt = f"Question: {question}\nAnswer:"

    response = openai.Completion.create(
        engine='text-davinci-003',
        prompt=prompt,
        max_tokens=500,  # Adjust the desired length of the answer
        n=2,  # Specify the number of responses to generate
        stop=None,  # You can provide a stopping condition if needed
        temperature=0.9  # Adjust the creativity level (higher values = more random)
    )

    if 'choices' in response and len(response['choices']) > 0:
        return response['choices'][0]['text'].strip()
    else:
        return ''

print("enter key")
concept = input()

extract_images(concept)

# extraction of dynamic constraints
headings = []


def get_wikipedia_headings(concept):
    url = f"https://en.wikipedia.org/w/api.php?action=parse&format=json&page={concept}"

    response = requests.get(url)
    data = response.json()

    if 'error' in data:
        # print(f"Error: {data['error']['info']}")
        return

    sections = data['parse']['sections']
    for section in sections:
        heading = section['line']
        headings.append(heading)

    return headings


# wikipedia function call
headings = get_wikipedia_headings(concept)
if not headings:
    headings = ["Definitions", "Advantages", "Disadvantages"]

# Taking user input
print("enter format")
op = int(input())
range1 = range(0, 4)
# Prompts and Required file generation
count = 0
if op in range1:
    print("Building the required format")
    for i in range(len(headings)):
        question = "What about %s of %s" % (headings[i], concept)
        count = count + 1
        answer = get_answer(question)
        book = answer
        with open('%s.txt' % (concept), 'a') as file:
            file.write('\t\t%s\n\n' % (concept))
            if (count == 1):
                file.write(' %s \n' % (headings[i]))
            else:
                file.write('\n\n %s \n' % (headings[i]))
            for i in book:
                file.write(i)

        if (count % 3 == 0):
            time.sleep(61)
        # print(answer)
        # print("\n")
    if _name_ == "_main_":
        api_key = "AIzaSyAjsKpGKCjUtxhJTrAuTSElHG_BK0eI5vg"
        video_links = get_video_links(concept, api_key)

        if video_links:
            with open('%s.txt' % (concept), 'a') as file:
                file.write("\n\n Video links related to %s :\n" % (concept))
                for link in video_links:
                    file.write(link)
                    file.write('\n')
                file.write("\n\n Images related to %s :\n" % (concept))
        else:
            with open('%s.txt' % (concept), 'a') as file:
                file.write("\n No video links found for %s : \n" % (concept))

    with open('%s.txt' % (concept), 'r') as file:
        lines = file.read()
    doc.add_paragraph(lines)

    image_files = [f for f in os.listdir(concept) if os.path.isfile(os.path.join(concept, f))]

    # Insert images between paragraphs
    for image_file in image_files:
        image_path = os.path.join(concept, image_file)
        doc.add_picture(image_path, width=Inches(4.0))  # Adjust width as needed

    # Document version
    doc.save("%s.docx" % (concept))
    # Epub version
    doc1 = aw.Document("%s.docx" % (concept))
    doc1.save("%s.epub" % (concept))

    files = os.listdir(source_folder)
    for file in files:
        source_path = os.path.join(source_folder, file)
        if (op == 1):
            if os.path.isfile(source_path) and file.lower().endswith('.txt'):
                destination_path = os.path.join(destination_folder, file)
                shutil.move(source_path, destination_path)

        if (op == 2):
            if os.path.isfile(source_path) and file.lower().endswith('.docx'):
                destination_path = os.path.join(destination_folder, file)
                shutil.move(source_path, destination_path)
        if (op == 3):
            if os.path.isfile(source_path) and file.lower().endswith('.epub'):
                destination_path = os.path.join(destination_folder, file)
                shutil.move(source_path, destination_path)

        for filename in os.listdir(source_folder):
            if filename.endswith('.py') and filename.endswith('.jpg'):
                continue
            file_path = os.path.join(source_folder, filename)
            if os.path.isfile(file_path):
                os.remove(file_path)
